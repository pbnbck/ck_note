### PFC优先级流量控制

PFC（Priority-based Flow Control，基于优先级的流量控制）也称为Per Priority Pause或 CBFC（Class Based Flow Control），是对Pause机制的一种增强。当前以太Pause机制（IEEE 802.3 Annex 31B）也能达到无丢包的要求，原理如下：当下游设备发现接收能力小于上游设备的发送能力时，会主动发Pause帧给上游设备，要求暂停流量的发送，等待一定时间后再继续发送数据。但是以太Pause机制的流量暂停是针对整个接口，即在出现拥塞时会将链路上所有的流量都暂停。

而PFC允许在一条以太网链路上创建8个虚拟通道，并为每条虚拟通道指定一个优先等级，允许单独暂停和重启其中任意一条虚拟通道，同时允许其它虚拟通道的流量无中断通过。这一方法使网络能够为单个虚拟链路创建无丢包类别的服务，使其能够与同一接口上的其它流量类型共存。

![image-20230921113937136](./images/some_concept/image-20230921113937136.png)

如图所示，DeviceA发送接口分成了8个优先级队列，DeviceB接收接口有8个接收缓存（buffer），两者一一对应（报文优先级和接口队列存在着一一对应的映射关系），形成了网络中 8 个虚拟化通道，缓存大小不同使得各队列有不同的数据缓存能力。

当DeviceB的接口上某个接收缓存产生拥塞时，即某个设备的队列缓存消耗较快，超过一定阈值（可设定为端口队列缓存的 1/2、3/4 等比例），DeviceB即向数据进入的方向（上游设备DeviceA）发送反压信号“STOP”。

DeviceA接收到反压信号，会根据反压信号指示停止发送对应优先级队列的报文，并将数据存储在本地接口缓存。如果DeviceA本地接口缓存消耗超过阈值，则继续向上游反压，如此一级级反压，直到网络终端设备，从而消除网络节点因拥塞造成的丢包。

参考https://support.huawei.com/enterprise/zh/doc/EDOC1100075566/d1e17776

“反压信号”实际上是一个以太帧，其具体报文格式如图所示

![download](./images/some_concept/download.png)

|  Destination address   | 目的MAC地址，取值固定为01-80-c2-00-00-01。                   |
| :--------------------: | ------------------------------------------------------------ |
|     Source address     | 源MAC地址。                                                  |
|       Ethertype        | 以太网帧类型，取值为88-08。                                  |
|     Control opcode     | 控制码，取值为01-01。                                        |
| Priority enable vector | 反压使能向量。其中E(n)和优先级队列n对应，表示优先级队列n是否需要反压。当E(n)=1时，表示优先级队列n需要反压，反压时间为Time(n)；当E(n)=0时，则表示该优先级队列不需要反压。 |
|    Time(0)～Time(7)    | 反压定时器。当Time(n)=0时表示取消反压。                      |
|          Pad           | 预留。传输时为0。                                            |
|          CRC           | 循环冗余校验。                                               |

总而言之，设备会为端口上的8个队列设置各自的PFC门限值，当队列已使用的缓存超过PFC门限值时，则向上游发送PFC反压通知报文，通知上游设备停止发包；当队列已使用的缓存降低到PFC门限值以下时，则向上游发送PFC反压停止报文，通知上游设备重新发包，从而最终实现报文的无丢包传输。

由此可见，PFC中流量暂停只针对某一个或几个优先级队列，不针对整个接口进行中断，每个队列都能单独进行暂停或重启，而不影响其他队列上的流量，真正实现多种流量共享链路。而对非PFC控制的优先级队列，系统则不进行反压处理，即在发生拥塞时将直接丢弃报文。

但是网络中如果出现大量PFC反压帧，则极有可能诱发网络死锁，出现两个或多个队列发生永久堵塞（等待），每个队列都在等待被其他队列占用并堵塞了的资源，最终导致网络系统性风险。智能无损网络提供了PFC死锁检测功能。当设备在死锁检测周期内持续收到反压帧时，将不会响应，确保不出现PFC死锁情况。

#### 哈希

哈希（Hash）是一种将任意大小的数据映射到固定大小值的过程。这个固定大小的值通常称为哈希值或哈希码。哈希函数是执行哈希操作的算法或函数。

哈希函数的主要特点包括：

1. **固定输出长度**：哈希函数将输入数据映射为固定长度的哈希值。无论输入数据的大小如何，哈希值的长度始终保持不变。
2. **相同输入产生相同哈希值**：对于相同的输入数据，哈希函数始终生成相同的哈希值。这是哈希函数的一致性特性。
3. **不同输入尽量生成不同的哈希值**：好的哈希函数会尽量确保不同的输入数据映射为不同的哈希值，以减少哈希冲突的概率。

### GRO

GRO（Generic Receive Offload）是一种网络性能优化技术，通常在网络适配器上实现，旨在提高网络数据包的接收性能和降低处理开销。以下是关于GRO的一些关键概念和工作原理：

1. **数据包合并**：GRO 的主要目标是合并多个传入网络数据包，将它们合并成更大的虚拟数据包。这个虚拟数据包仍然包含了原始数据包的全部数据，但通过减少处理多个小数据包的开销，提高了网络栈的性能。
2. **降低中断处理频率**：在传统网络堆栈中，每个接收到的数据包通常会触发一个中断，导致 CPU 去处理每个数据包的接收和分发。使用GRO，多个数据包可以在单个中断中一起处理，减少了中断处理的频率，从而降低了CPU的负载。
3. **工作原理**：GRO通常在网络适配器或网络驱动程序中实现。当多个数据包到达适配器并且它们都满足一些特定条件时（例如，它们具有相同的目的地址和端口），适配器将它们合并成一个虚拟数据包。然后，虚拟数据包被传递到操作系统的网络堆栈中，如TCP/IP协议栈。应用程序或协议栈将虚拟数据包拆分为原始数据包以进一步处理。
4. **性能提升**：GRO可以显著提高网络性能，特别是在高速网络中。通过减少中断处理的次数和降低CPU的负载，它可以提高系统的吞吐量和响应时间，特别是在有大量小数据包传输的情况下。

需要注意的是，GRO并非适用于所有情况。有些应用程序可能需要立即处理每个单独的数据包，而不合并它们。因此，GRO通常可以在需要时进行配置或禁用，以根据具体的网络流量和应用程序需求来进行调整。

### DPDK

#### 为什么有dpdk

以 Linux 内核协议栈为基础的网络方案存在许多瓶颈，无法高性能地处理数据包

​        此时需要个解决方案来消除这些瓶颈，同时保持与原有 Linux 应用程序的兼容 另外，新方案还应该适合以库的形式打包到 Linux 发行版中，在用户需要时用来管理各种网络设备这些目标最初是在 2010 年实现的，当时 Intel 基于 Nehalem 微架构的 Xeon 处理器推出了 DPDK的初始版本 DPDK 绕过 (bypass) Linux 内核，在用户态执行数据包处理 以提供尽可能高的网络性能。DPDK 程序运行在操作系统的用户态，利用自带的“数据平面库”进行数据包的发送、处理和接收，绕过了运行在内核态的 Linux 网络协议栈，提升了数据包处理效率展示DPDK 在软件架构上与内核协议栈方案的差异。

![image-20230922090048387](./images/some_concept/image-20230922090048387.png)

​         不过， Linux 内核仍然是 DPDK 实现的基础，比如内核中的 UIO 驱动框架，它为 DPDK驱动程序提供了获取寄存器地址和长度、地址映射和读取中断计数等功能（具体如何以及是否使用这些功能，还要看 DPDK 驱动程序的具体实现）。另外，内核提供的“大页“机制也DPDK 进行内存管理的重要手段

​        DPDK 的网卡驱动程序运行在用户态 其屏蔽了网卡硬件发起的大部分（除了断链、错误等类型的）中断，采用主动轮询的模式，待续检查网卡的接收／发送队列，查看是否有新数据到达或者是否可以继续发送数据，从而实现高吞吐械和低时延 因此， DPDK 的驱动程序被称为轮询模式驱动程序 (poll mode driver, PMD)





#### DPDK体系结构

​        DPDK 为需要快速处理数据包的数据平面应用提供了一个简单、完整的框架。该框架通过创建环境抽象层 (envonment abstraction layer, EAL) ，为特定环境提供组库这里提到的特定环境，指的是 CPU 体系结构（比如 32 位或 64 x86 处理器）、 GCC 编译器或某些特定的平台这些环境通过使用 meson 文件和配置文件来指定。一旦创建了EAL 库，用户就可以与该库链接以执行自己的应用程序 DPDK 也提供了EAL 之外的其他库，比如哈希(hash) 、最长前缀匹配 (LPM) 库等 此外， DPDK 代码中的示例应用程序可以帮助用户了解如何使用 DPDK 提供的各种功能。

​       DPDK 为处理数据包实现了一个“运行到完成 “(run to completion) 的模型，在执行数据平面处理逻辑之前，必须先分配所有资源，然后以逻辑核上执行单元（线程）的形式运行该模型不支持调度器，以轮询的方式访问所有设备处理数据包时不使用中断，主要原因是中断处理会产生较大的性能开销。

##### 核心组件

​     DPDK 中的核心组件是组库，这些库为应用程序提供了高性能处理数据包所需的所有元素下图展示了 DPDK 的核心组件（库）以及它们之间的依赖关系。库的名称中 rte 前缀











### RDMA	

RDMA是一种概念，在两个或者多个计算机进行通讯的时候使用DMA， 从一个主机的内存直接访问另一个主机的内存。

![img](./images/some_concept/v2-f081e8fce13d8b00e5a786399d20ca06_r.jpg)

RDMA是一种host-offload, host-bypass技术，允许应用程序(包括存储)在它们的内存空间之间直接做数据传输。具有RDMA引擎的以太网卡(RNIC)--而不是host--负责管理源和目标之间的可靠连接。使用RNIC的应用程序之间使用专注的QP和CQ进行通讯：

QP 是 Queue Pair 的缩写，表示队列对。

#### 相关概念

1.发送请求（SR）

- - SR定义了数据的发送量、从哪里、发送方式、是否通过 RDMA、到哪里。 结构 ibv_send_wr 用来描述 SR。

2.接收请求（RR）

- - RR 定义用来放置通过RDMA 操作接收到的数据的缓冲区。如没有定义缓冲区，并且有个传输者尝试执行一个发送操作或者一个带即时数的 RDMA写操作，那么接收者将会发出接收未就绪的错误（RNR）。结构 ibv_recv_wr用来描述 RR。

3.完成队列（CQ）

- - （CQ）完成队列包含了发送到工作队列（WQ）中已完成的工作请求（WR）。每次完成表示一个特定的 WR 执行完毕（包括成功完成的 WR 和不成功完成的 WR）。完成队列是一个用来告知应用程序已经结束的工作请求的信息（状态、操作码、大小、来源）的机制。
  - CQ有n个完成队列实体（CQE）。CQE的数量在CQ创建时指定。当一个CQE被轮询到，他就从CQ中被删除。CQ是一个CQE的先进先出（FIFO）队列。CQ能服务于发送队列、接收队列或者同时服务于这两种队列。多个不同QP中的工作请求（WQ）可联系到同一个CQ上。结构ibv_cq用来描述CQ。

4.内存注册（MR）

- - 内存注册机制允许应用程序申请一些连续的虚拟内存或者连续的物理内存空间，将这些内存空间提供给网络适配器作为虚拟的连续缓冲区，缓冲区使用虚拟地址。内存注册进程锁定了内存页。为了防止页被替换出去，同时保持物理和虚拟内存的映射。在注册期间，操作系统检查被注册块的许可。注册进程将虚拟地址与物理地址的映射表写入网络适配器。在注册内存时，对应内存区域的权限会被设定。权限包括本地写、远程读、远程写、原子操作、绑定。
  - 每个内存注册（MR）有一个远程的和一个本地的标志（r_key,l_key）。本地标志被本地的 HCA 用来访问本地内存，例如在接收数据操作的期间。远程标志提供给远程 HCA 用来在 RDMA 操作期间允许远程进程访问本地的系统内存。同一内存缓冲区可以被多次注册（甚至设置不同的操作权限），并且每次注册都会生成不同的标志。结构ibv_mr用来描述内存注册。

5.内存窗口（MW）

- - 内存窗口使应用程序对来自远程对本地的内存访问有更灵活的控制。内存窗口作用于以下场景：1）动态地授予和回收已注册缓冲区的远程访问权限，这种方式相较于将缓冲区取消注册、再注册或者重注册，有更低的性能损耗代价。2）想为不同的远程代理授予不同的远程访问方式，或者在一个已注册的缓冲区中不同范围授予哪些权限。内存窗口和内存注册之间的关联操作叫做绑定。不同的MW可以做用于同一个MR，即使有不同的访问权限。

6.地址向量（Address Vector）

- - 地址向量用来描述本地节点到远程节点的路由。在QP的每个UC/RC中，都有一个地址向量存在于QP的上下文中。在UD的QP中，每个提交的发送请求（SR）中都应该定义地址向量。结构ibv_ah用来描述地址向量。

7.全局路由头部（GRH）

- - GRH用于子网之间的路由。当用到RoCE时，GRH用于子网内部的路由，并且是强制使用的，强制使用GRH是为了保证应用程序即支持IB又支持RoCE。当全局路由用在给予UD的QP时，在接受缓冲区的前40自己会包含有一个GRH。这个区域撞门存储全局路由信息，为了回应接收到的数据包，会产生一个合适的地址向量。如果向量用在UD中，接收请求RR应该总是有额外的40字节用来GRH。结构ibv_grh用来描述GRH。

8.保护域（PD）

- - 保护域是一种集合，它的内部元素只能与集合内部的其它元素相互作用。这些元素可以是AH、QP、MR、和SRQ。保护域用于QP与内存注册和内存窗口相关联，这是一种授权和管理网络适配器对主机系统内存的访问。PD也用于将给予不可靠数据报（UD）的QP关联到地址处理（AH），这是一种对UD目的端的访问控制。
